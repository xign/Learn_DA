{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv('ex1data2.txt', header=None, names=['x1', 'x2', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[['x1', 'x2']].values\n",
    "Y = data['y'].values\n",
    "m = len(data)\n",
    "theta = np.zeros(3)\n",
    "iterations = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_normalize(X):\n",
    "    #   FEATURENORMALIZE Normalizes the features in X \n",
    "    #   FEATURENORMALIZE(X) returns a normalized version of X where\n",
    "    #   the mean value of each feature is 0 and the standard deviation\n",
    "    #   is 1. This is often a good preprocessing step to do when\n",
    "    #   working with learning algorithms.\n",
    "\n",
    "    # You need to set these values correctly\n",
    "    X_norm = X\n",
    "    mu     = np.zeros(X.shape[1])\n",
    "    sigma  = np.zeros(X.shape[1])\n",
    "    \n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    # Instructions: First, for each feature dimension, compute the mean\n",
    "    #               of the feature and subtract it from the dataset,\n",
    "    #               storing the mean value in mu. Next, compute the \n",
    "    #               standard deviation of each feature and divide\n",
    "    #               each feature by it's standard deviation, storing\n",
    "    #               the standard deviation in sigma. \n",
    "    #\n",
    "    #               Note that X is a matrix where each column is a \n",
    "    #               feature and each row is an example. You need \n",
    "    #               to perform the normalization separately for \n",
    "    #               each feature. \n",
    "    #\n",
    "    # Hint: You might find the 'np.mean' and 'np.std' functions useful.\n",
    "    #  \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ============================================================\n",
    "    \n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_norm, mu, sigma = feature_normalize(X)\n",
    "X_norm = np.insert(X_norm, 0, 1, 1)\n",
    "X_norm[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose some alpha value\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your implementations of compute_cost and gradient_descent work when X has more than 2 columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost_multi(X, y, theta):\n",
    "    # COMPUTECOSTMULTI Compute cost for linear regression\n",
    "    # J = COMPUTECOSTMULTI(X, y, theta) computes the cost of using theta as the\n",
    "    # parameter for linear regression to fit the data points in X and y\n",
    "    \n",
    "    # some useful values\n",
    "    m = len(X)\n",
    "    \n",
    "    # You need to return this value correctly:\n",
    "    J = 0\n",
    "    \n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    # Instructions: Compute the cost of a particular choice of theta\n",
    "    #               You should set J to the cost.\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ============================================================\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_cost_multi(X_norm, Y, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_multi(X, y, theta, alpha, num_iters):\n",
    "    # GRADIENTDESCENT Performs gradient descent to learn theta\n",
    "    # theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by \n",
    "    # taking num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    # Initialize\n",
    "    J_history = np.zeros(num_iters)\n",
    "    T_history = np.zeros((num_iters,X.shape[1]))\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        T_history[i] = theta\n",
    "\n",
    "        ### ========= YOUR CODE HERE ============\n",
    "        # Instructions: Perform a single gradient step on the parameter vector theta.\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ### =====================================\n",
    "        \n",
    "        J_history[i] = compute_cost_multi(X, y, theta)\n",
    "    return theta, J_history, T_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta, J_history, T_history = gradient_descent_multi(X_norm, Y, theta, alpha, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theta found by gradient descent: (should be [ 340412.65957447,  109447.79646964,   -6578.35485416])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pandas.Series(J_history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the price of a 1650 sqft, 3 bedroom house:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Estimate the price of a 1650 sq-ft, 3 br house\n",
    "# ====================== YOUR CODE HERE ======================\n",
    "# Recall that the first column of X is all-ones. Thus, it does\n",
    "# not need to be normalized.\n",
    "\n",
    "price = 0\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Equasions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pandas.read_csv('ex1data2.txt', header=None, names=['x1', 'x2', 'y'])\n",
    "X = data[['x1', 'x2']].values\n",
    "Y = data['y'].values\n",
    "X = np.insert(X, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_eqn(X, y):\n",
    "    #NORMALEQN Computes the closed-form solution to linear regression \n",
    "    #   NORMALEQN(X,y) computes the closed-form solution to linear \n",
    "    #   regression using the normal equations.\n",
    "\n",
    "    theta = np.zeros(X.shape[1]);\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    # Instructions: Complete the code to compute the closed form solution\n",
    "    #               to linear regression and put the result in theta.\n",
    "    #\n",
    "\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = normal_eqn(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theta found using the normal equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price estimation of a 1650sqft house with 3 bedrooms, using theta from the normal equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([1, 1650, 3]).dot(theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
